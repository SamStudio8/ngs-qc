%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Results}
\section{Introduction}
\subsection{Why Decision Trees?}
\subsection{CART}

\section{Parameter Selection}
...important to find the "best" parameters
...what is best? scikit-learn uses total gini information

...frontier uses two methods:
\begin{itemize}
    \item Backward elimination; pruning parameters with the lowest total gini
    \item Call scikit-learn's SelectKBest
\end{itemize}


* incorrect degrees of freedom
* warnings: /usr/lib64/python2.7/site-packages/sklearn/feature\_selection/univariate\_selection.py:256: RuntimeWarning: invalid value encountered in divide, causing NaN
* Replaced univariate\_selection with version from master
* needed use force np.float64
* ...actually data was 0... gg


\section{Trees}
\subsection{Initial Trees}
\subsection{Parameter Sets}

Identified a series of parameter sets for initial training and testing purposes:

\begin{itemize}
    \item \textbf{AQC} \hfill\\
        A set consisting of all available parameters used by \textbf{auto\_qc}.
    \item \textbf{AQCN} \hfill\\
        Replaces groups of the \textbf{AQC} set with aggregated parameters.
    \item \textbf{ERROR} \hfill\\
        An experimental toy set consisting of only the "error-rate" parameter.
    \item \textbf{NO\_ERROR} \hfill\\
        Another toy set designed to test results gained by excluding the
        "error-rate" parameter.
    \item \textbf{BASELINE} \hfill\\
        Include any parameter which include "baseline" as a substring.
    \item \textbf{NOBASELINE} \hfill\\
        Exclude any parameter which include "baseline" as a substring.
    \item \textbf{MARP} \hfill\\
        Include any parameter which includes one of the following substrings:
        mean, percent, rate or average.
    \item \textbf{NO\_MARP} \hfill\\
        Exclude any parameter which includes one of the following substrings:
        mean, percent, rate or average.
\end{itemize}

Of note in particular is the \textbf{AQC} set, constructed from the parameters
available from the "BAMcheckr'd" data that are taken in to account by the
current \textbf{auto\_qc} system. It should be noted however that not all these
parameters were initially available in the input files and \textbf{auto\_qc}
relies upon data made available from \textbf{vr-pipe} where the rules of
\textbf{auto\_qc} are actually applied. Appendix~\ref{app:ratios} discusses
contributions I made to \textbf{bamcheckr} for recovering these parameters for
use in our analysis. Ultimately, \textbf{bamcheckr} performed too slowly and it
was possible to use \textbf{Frontier} itself to extract the additional features
needed to better represent the decisions made by the current system.

\begin{table}
    \centering
    \begin{tabular}{l | c  c  c  c  r}
        Set           & Nº & CV  & ± SD & Depth & Most Important Feature\\
        \hline
        ALL           & 86 & 97 & 1 & 38 & T-percent-max-baseline-deviation (27\%)\\
        AQC           & 27 & 95 & 1 & 36 & T-percent-max-baseline-deviation (31\%)\\
        AQCN          & 21 & 95 & 1 & 39 & max-max-baseline-deviation (31\%)\\
        ERROR         & 1  & 61 & 2 & 53 & error-rate (100\%)\\
        NO\_ERROR     & 85 & 97 & 1 & 38 & T-percent-max-above-baseline(27\%)\\
        BASELINE      & 34 & 89 & 1 & 46 & T-percent-max-above-baseline(28\%)\\
        NOBASELINE    & 52 & 91 & 1 & 31 & error-rate (24\%)\\
        MARP          & 47 & 95 & 1 & 39 & T-percent-max-above-baseline (27\%)\\
        NO\_MARP      & 39 & 87 & 1 & 38 & max-max-baseline-deviation (34\%)\\
    \end{tabular}

    \caption[pset-cv]{\textbf{Parameter Set Cross Validation Scores}: Columns
        left to right; parameter set name, number of parameters included,
        average cross-validation score (max 100), standard deviation of scores,
        average depth of the generated tree and the most important parameter by
    Gini importance (max 100).}

    \label{tab:pset-cv}
\end{table}

%TODO Cite dtc
For each parameter set, data and targets were extracted via \textbf{Frontier}'s
API before being subset by \textbf{scikit-learn}'s \textbf{StratifiedKFold}
function. These subsets are referred to as "folds" (of which we used 10) and for
each fold a \textbf{DecisionTreeClassifier} was trained and tested.
Table~\ref{tab:pset-cv} outlines the cross validation scores for each such
experiment.

...highlights the shortcomings of using a decision tree...
overfitting... gini coefficient not a real measure of importance...

\begin{listing}[H]
    \caption[frontier-warnings]{\textbf{Frontier Variance Warnings}:
        Warnings issued for \textbf{auto\_qc} parameters that have been found to
        have no variance by one of \textbf{Frontier}'s sanity checking procedures.}
    \label{list:frontier-warnings}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=0,
                frame=lines,
                framesep=2mm]{bash}
/pools/encrypted/sanger/frontier/data/bamcheck_2013dec25_ratios_out/(13455 files)
[WARN] bases-trimmed parameter has 0 variance (with mean 0.00)
[WARN] filtered-sequences parameter has 0 variance (with mean 0.00)
[WARN] is-paired parameter has 0 variance (with mean 1.00)
[WARN] is-sorted parameter has 0 variance (with mean 1.00)
[WARN] maximum-length parameter has 0 variance (with mean 100.00)
[WARN] non-primary-alignments parameter has 0 variance (with mean 0.00)
[WARN] quality-dropoff-high-iqr-threshold parameter has 0 variance (with mean 10.00)
[WARN] quality-dropoff-ignore-edge-cycles parameter has 0 variance (with mean 3.00)
[WARN] quality-dropoff-runmed-k parameter has 0 variance (with mean 25.00)
    \end{minted}
\end{listing}

Parameters with no variance will have constant value across all observations
regardless of their class label and will thus be unhelpful in predicting class
membership for future observations. Such parameters can be safely discarded,
Listing~\ref{list:frontier-warnings} displays warnings issued by
\textbf{Frontier} for several of the \textbf{auto\_qc}

\subsection{Parameter Selection}

Whilst the crude parameter sets of the previous section were useful to gain
understanding of the data that we have, it was necessary to obtain more
deliberate decisions for parameters to utilise in the model.

\subsection{Ignoring Warnings}

\subsubsection{Cross Validation}

...method in which to measure classification accuracy...
...potentially use a weighting to penalise mistakes in smaller classes...

...K fold cross validation
...using stratified K fold cross validation...

\subsubsection{Confusion Matrices}
"Normal" confusion matrix and "Warnings" confusion matrix...

