\chapter{Frontier}
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%TODO Better description of Frontier
This chapter introduces \textbf{Frontier}: the main programming effort for this
part of the project. Frontier is a Python package that serves as a data manager,
providing both interfaces to read inputs into structures in memory and to
retrieve them in formats acceptable to a machine learning framework.

\section{Design}
\subsection{Purpose}

Frontier's purpose is to supplement analysis with \textbf{scikit-learn} by
allowing a user to read in and parameterise data in a format that can then be
used for analysis by the \textbf{scikit-learn} library.  Frontier was designed
to simplify the process of setting up machine learning tasks and enable
experiment repeatability by removing the need for users to spend time
constructing classes and functions to parse their input data and to just get on
with analysis using \textbf{scikit-learn}.

Initially Frontier was to act as a wrapper around \textbf{scikit-learn},
essentially removing the end user's interaction with the library and merely
providing an interface for data to be passed in and some sort of classifier to
be returned. However this quite clearly limited Frontier's audience by tying it
to a particular framework and would quickly become unmanageable in the task of
providing wrappers for all aspects of an external library.

Instead it was decided that Frontier would be used alongside a user's chosen
machine learning framework, providing a useful API to parse and extract
observations and variables from input data and arrange them in structures
suitable for processing with \textbf{scikit-learn}.

If possible, Frontier could also handle any objects returned, displaying or
logging any textual or graphical information pertaining to a returned
classifier's accuracy to assist a user in the ongoing performance monitoring of
changes to used data subsets or parameters.


\subsection{Format}

Frontier is designed as a Python package, allowing a user to import its
functionality in to other programs. The result of this project's technical
output could almost be considered as two separate entities: Frontier itself, the
package designed to ease user interaction with scikit-learn and \textbf{Front},
a Python script which implements Frontier's functionality in order to interact
with scikit-learn to conduct analysis on the \textbf{auto\_qc} data.


\subsection{Method}

.. the result of abstracting code and tools created during the use of
\textbf{scikit-learn} for analysis of the current \textbf{auto\_qc} system
.. initially hard-coded to suit the specific needs of the project but followed
an evolutionary design process...

designed specifically for the given learning problem, with hard coded
classes and encodings...


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Concepts}

In this section we introduce some terminology and ideas that will assist
understanding of the application's purpose and terminology used in the following
implementation section.


\subsection{Observations and Parameters}

An \textbf{observation} refers to a distinct object or "thing" from which we
will attempt to understand the relationship between its known properties and
classification to be able to label future observations with unknown class based
on those properties. In the context of this project, this would be a lanelet.
Other documentation in the field may use the term \textit{sample} but to avoid
confusion with the definition of sample introduced in
Chapter~\ref{chap:samplelanelanelets} we will use the term observation.

The aforementioned \textit{properties} or \textit{attributes} of an observation
will be referred to as the \textbf{parameters} of that observation.
Traditionally these may be described as \textit{features} but it was felt that
this wording may have connotations with discrete data. Early versions of
Frontier referred to parameters as \textit{regressors}, using terminology from
statistical modelling. This wording was dropped to remove any confusion between
regression and classification machine learning problems.


\subsection{Data and Targets}
%TODO Mention dependent and explanatory variables?

\textbf{Data} will be used somewhat generically to refer to a matrix in which
observations act as rows and their parameters act as columns. It is expected
that all observations will have the same set of parameters.

For problems of a classification nature such as ours, an observation's
\textbf{target} is the known classification of that particular observation.
Depending on the context of the learning problem targets may be discovered
manually (\textit{e.g.} counting leaves from images of plants, one will need to
manually count all the leaves in the image before being able to use it for
learning) or as the output from another system such as \textbf{auto\_qc}.

In the context of this project where the objective is to begin learning the
rules of \textbf{auto\_qc} the targets refer to whether a particular lanelet
observation was labelled as a pass, fail or warn by the current system.


\subsection{Class Labels and Codes}
\label{chap:labelcode}

An observation's target may also be known as its \textbf{label}. A labelled
observation is said to be a member of that label's \textbf{class}. For example a
lanelet that has failed \textbf{auto\_qc} is said to be labelled as a fail and
is a member of the class of failures.

String based class labels can pose difficulties when handling data later on, not
only taking more memory to store as opposed to a type such as an integer but
also introducing accidental subsetting or discarding of data whose labels differ
unexpectedly. For example are "fail", ,"fial", "FAIL" and "Failed" supposed to
be members of the same class?

%TODO Why?
Often such labels are \textbf{encoded} in to simpler types such as integers.


\subsection{Training and Testing}

...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}

This section investigates the implementation of Frontier's major components:

\begin{itemize}
    \item Informing the package of the problem domain...
    \item Interfaces provided for reading in data
    \item Storage of read data in memory
    \item Retrieval of stored data
    \item Interaction with scikit-learn
\end{itemize}


\subsection{Class Definitions}
\label{chap:classes}

Frontier was designed to support classification machine learning problems, to
adequately support this task, the package must be aware of each of the possible
classes in the problem space. Early versions of Frontier were specifically
designed for training and testing data from \textbf{auto\_qc} and could only
support encoding and decoding of the pass, fail and warn classes.

However this implementation was clearly esoteric and held little to no further
use outside the domain of the project's learning task. What would happen if a
class label were to be added or removed in future? Most likely many lines of
code would need to be re-written to handle such cases; the package was
inflexible.

To counter this, Frontier was refactored to remove hard coded label definitions
enabling its use as a more general purpose tool where users can specify the
domain's classes and their associated labels and encodings.
Listing~\ref{list:FrontierClasses} shows the definitions used by Front to work
with the \textbf{auto\_qc} data.

\begin{listing}[H]
    \caption[FrontierClasses]{: Class definitions for \textbf{auto\_qc} as passed to Frontier}
    \label{list:FrontierClasses}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}
        CLASSES = {
                "pass": {
                    "names": ["pass", "passed"],
                    "code": 1,
                },
                "fail": {
                    "names": ["fail", "failed"],
                    "code": -1,
                },
                "warn": {
                    "names": ["warn", "warning"],
                    "code": 0,
                },
        }
    \end{minted}
\end{listing}

As per Listing~\ref{list:FrontierClasses}, to define classes a user must provide
a Python dict containing the following for each label:

\begin{itemize}
    \item \textbf{class} \textit{String}\hfill\\
        The dictionary key is used as the canonical name of the class label
    \item \textbf{names} \textit{[String]}\hfill\\
        A list of labels that denote membership of this class
    \item \textbf{code} \textit{Integer}\hfill\\
        The encoded representation of this class (See Chapter~\ref{chap:labelcode})
    \item \textbf{\_recode} \textit{Boolean, Private}\hfill\\
        A flag to indicate whether an API action has changed the code of this
        class, typically used when treating all members of one class as a member
        of another -- A user should never set this manually
    \item \textbf{\_count} \textit{Integer, Private}\hfill\\
        The number of observations with this label, typically used when
        calculating weightings based on the proportions of class sizes and
        outputting logging information -- A user should not set this manually
\end{itemize}

This simple structure allows Frontier to be compatible with almost any
classification learning task with minimum input from the end user. Additional
utilities provided by the Frontier utils subpackage use this structure to
automatically classify and encode labels without user intervention with the
following functions:

\begin{itemize}
    \item \textbf{classify\_label} \hfill\\
        Attempt to classify a label by comparing a given string to each set of
        \textit{names}, locating an exact match will return the relevant
        canonical class label
    \item \textbf{encode\_class} \hfill\\
        Given a canonical class label, return its \textit{code}
    \item \textbf{decode\_class} \hfill\\
        Given a \textit{code}, return the canonical class label unless
        \textit{\_recode} is True
    \item \textbf{count\_class} \hfill\\
        Increment the \textit{\_count} for a particular class given its
        canonical label
\end{itemize}

These functions are put to use throughout Frontier and are essential for reader
classes (detailed in the next chapter) to parse, classify and then encode
observation targets automatically from relevant files.


\subsection{Input Handling}

Frontier's modular nature allows users to write their own Python classes to read
data from any form of input file or stream. Two examples of which are the
classes used to read from the "bamcheckr'd files" documented in
Appendix~\ref{app:bamcheckr} and the \textbf{auto\_qc} decisions matrix briefly
demonstrated in Appendix~\ref{app:aqc_matrix}.

These classes are described as \textbf{Readers} and implement a common base
class, \textbf{AbstractReader} which takes care of
setting up the file handler, including functions to both close and iterate over
the file's contents. It will also automatically call its own
\textbf{process\_file} function that skips over any header lines before passing
each line in the file stripped of any newline characters to \textbf{process\_line}.

It is expected that derived classes will at least provide their own
implementations for \textbf{process\_line} and \textbf{get\_data}. Failing to do
so will cause Frontier to throw a \textbf{NotImplementedError} when attempting
to use the class to read data.

%TODO Better describe process line expectations (locate key, value)?
\textbf{process\_line} defines the line handling operations that extract and store
desired data found in a given line. This responsibility includes returning None
for lines that contain comments and irrelevant data.

\textbf{get\_data} must return any read in data in a suitable structure for
storage by Frontier. Typically this will be a Python dictionary using some
unique identifier for each observation as a key, mapping to an arbitrary value
or object containing that observation's parameters. Further discussion on
Frontier's storage of data and targets is to follow.

The \textbf{AbstractReader} class is designed to simplify the process of reading
in observations and their targets for end users, however it is still up to the
author of the dervied class to set up any structures to store data (which cannot
be done automatically without likely enforcing potentially unhelpful
constraints) before initialisation of the inherited base class (via the call to
\textbf{super}) as shown in Listing~\ref{list:superreader}.

\begin{listing}[H]
    \caption[superreader]{: Extract from \textbf{BamcheckReader} class
        documenting initialisation of necessary data structures and calling
        for initialisation of its inherited base class}
    \label{list:superreader}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}
        class BamcheckReader(AbstractReader):
            [...]

            def __init__(self, filepath, CLASSES, auto_close=True):
                self.summary = SummaryNumbers()
                self.indel = IndelDistribution()
                super(BamcheckReader, self).__init__(filepath, CLASSES, auto_close, 0)

            [...]
    \end{minted}
\end{listing}

As shown in Listing~\ref{list:superreader}, the initialisation of the
\textbf{AbstractReader} allows four arguments:

\begin{itemize}
    \item \textbf{filepath} \textit{String}\hfill\\
        A relative or absolute path to a file from which to extract data or
        targets
    \item \textbf{CLASSES} \textit{Dictionary}\hfill\\
        A dictionary of user specified class labels defined as described in
        the previous chapter
    \item \textbf{auto\_close} \textit{Boolean, Optional}\hfill\\
        Whether or not to close the file handle immediately after executing
        \textbf{process\_file}, this is True by default to prevent either memory
        leaking when users are reading in a large number of files and are
        perhaps unaware that they require closing or the throwing of an IOError
        caused by having too many file handles open at once
    \item \textbf{header} \textit{Integer, Optional}\hfill\\
        The number of lines to ignore before the reader should begin
        passing stripped lines to \textbf{process\_line}, defaults to 0
\end{itemize}

Currently it is also the responsibility of the author of a derived class to
perform relevant sanity checking of any extracted data. For example the
\textbf{BamcheckReader} class checks for the presence of multiple entries of a
particular metric which will print a notice if found, unless the entries have
differing values, upon which an exception is thrown and the process is halted.

Once a reader has been defined for a particular file format, a user need only
provide a directory of files to be parsed and the name of the class designed to
complete the parsing. Frontier will then take care of executing the parsing
process on all files in the directory. After a derived reader has completed file
handling, Frontier will call its \textbf{get\_data} function to
"move"\footnote{Rather, a pointer to the address of the extracted data's
dictionary hashmap will be copied to memory inside a Frontier class} the
extracted data to its own storage.

%TODO Cite algorithm
At this point Frontier will also check the integrity of the data, primarily that
all parameters have a non-zero variance. Users will be warned when this
requirement is violated; parameters with no variance cannot provide much
information for successful classification as their values are equal for all
class labels!

%FUTURE
In future it would be useful to investigate whether it would be feasible to
perform such sanity checking in a generic manner to ensure it could be applied
to a wide enough range of scenarios to make it worth including functionality in
the \textbf{AbstractReader} directly.

With more time, future improvements could overhaul the reader interfaces
to allow users to simply specify the format of a file in a string that can be
parsed by Frontier's IO subpackage, rather than having to write their own derived
class. Classes could also list file extensions they are capable of processing
which could potentially be used to automatically determine which readers to use
without requiring the user to explicitly specify.


\subsection{Storage}

% TODO Cite tests?
Frontier specifies a class called the \textbf{Statplexer}\footnote{A somewhat
contrived contraction of 'Statistics Multiplexer'} which provides users with a
single point of access to all read in data. The reader interfaces described in
the previous chapter implement their own loading functions to populate the
\textbf{\_data} and \textbf{\_targets} class members of the \textbf{Statplexer}
object.

%TODO Find better citation (Python book)
%TODO Introduce Python dictionaries in Concepts ?

\textbf{\_data} and \textbf{\_targets} are Python dictionaries, a structure in
which hashed keys are mapped to an arbitrary value or object. During the parsing
of observation data with the relevant reader class, the reader is expected to
locate an appropriate unique ID for each observation. In the case of processing
of \textbf{auto\_qc} data, this would be the lanelet's barcode which is
collected from the filename of that particular lanelet's "bamcheckr'd" file.

This identifier is then used as a key in both the \textbf{\_data} and
\textbf{\_targets} dictionaries to map to a structure (typically another
dictionary or an arbitrary class) that stores that observation's parameters
and its known target (encoded class label), respectively.

Although these attributes can be manipulated directly (and indeed they are for
testing purposes) the leading underscore follows a popular convention defined in
Python's style guideline, PEP8\citep{pep8}, where class members with leading
underscores should be treated as non-public. Python doesn't have private
variables such as those that may be found in other languages like Java, indeed
the Python style guide points out that "no attribute is really private in
Python"\citep{pep8}. In an interesting StackOverflow answer on the subject, a
user describes that this is "cultural"\citep{so:pythonprivate} and that Python
programmers are trusted not to circumvent convention and "mess around with those
private members". Users are therefore expected to use the functionality
Frontier provides for controlled getting and setting of data stored in these
pseudo-private \textbf{\_data} and \textbf{\_targets} members.

For example, \textbf{load\_data} should be used exclusively when populating
the two dictionaries and is automatically called on construction of the
\textbf{Statplexer} if the arguments are valid. \textbf{load\_data} will
automatically call other (pseudo-private) functions of the class including
\textbf{\_test\_variance} which checks that parameter variances are non-zero
whilst also warning users if new observations are overwriting old ones or
if an observation does not appear to have a corresponding target.

...Python
dictionaries offer (constant) lookup access and more importantly querying the
structure for whether it contains a particular key can also be performed in
constant $O$(1) as opposed to searching a list for
membership\citep{py:timecomplexity}...

...The following section describes the retrieval of data and targets in the
form of lists or \textbf{numpy} arrays... so why not just store read in data
in one of these structures to begin with instead?

This is primarily due to the underlying layout of a list structure, which must
be represented in memory as a contiguous block. Great expense is therefore
incurred if the list grows beyond its bounds and must be relocated to resize.
Given the nature of input data, the number of observations and their parameters
are unknown before the input data is read and so memory cannot be reserved to
prevent these operations.

It is arguable that despite this, the data could be unloaded from the
\textbf{\_data} and \textbf{\_targets} dictionaries in to some form of array at
the end of the call to \textbf{load\_data}. However the \textbf{Statplexer}
allows loading of data at any time, which would not only risk increasingly
expensive resizing operations as the list continues to expand but the sanity
checking that takes place in \textbf{load\_data} involves checking for
membership of an ID in \textbf{\_data} and \textbf{\_targets} where performance
is constant for dictionaries and $O$(n) for lists.

...although the latter point is somewhat easily fixed for an array
implementation by using a dictionary to provide a mapping between a sample name
and where it is stored in an array...

...an issue with use of a dictionary however is by default they are unsorted,
not only this but the order in which the keys are iterated over will be
undefined...

...currently this causes the list of keys to require sorting each time a user
queries the Statplexer API for data... as obviously the parameters and targets
must map one-to-one in a predictable and repeatable manner.
%TODO Figure to show mapping between container elements

It should be noted that the \textbf{Statplexer} stores a copy of the user
defined CLASSES dictionary (as the class member \textbf{\_classes}), which is an
argument to its construction, allowing the \textbf{Statplexer} to share this
information with any readers or utility functions who require it.


\subsection{Retrieval}

The Statplexer is designed to provide functions to an end user for extraction
of desired data in a format suitable for an external framework or library,
in our case; scikit-learn...

...leverages \textbf{numpy}...

...Frontier can be used to inspect the parameter set extracted from the
observations... some of the methods provided for this purpose include:

\begin{itemize}
    \item \textbf{list\_parameters} \hfill\\
        Return a sorted list of all parameters
    \item \textbf{find\_parameters} \hfill\\
        Given a list of input strings, return a list of parameters which contain
        any of those strings as a substring
    \item \textbf{exclude\_parameters} \hfill\\
        Given a list of input strings, return a list of parameters which do not
        contain any of the input strings as a substring, or if needed an exact
        match
\end{itemize}

...data is returned sorted by key,
...with parameters sorted alphanumerically...
...targets map 1:1 with the data array...

\begin{itemize}
    \item \textbf{get\_data\_by\_parameters} \hfill\\
        Return data for each observation, but only include columns
        for each parameter in the given list
    \item \textbf{get\_data\_by\_target} \hfill\\
        Return data for each observation that have been classified in one of the
        targets specified and additionally only return columns for the
        parameters in the given list
\end{itemize}

\subsection{Interaction with scikit-learn}
\subsubsection{Cross Validation}

...method in which to measure classification accuracy...
...potentially use a weighting to penalise mistakes in smaller classes...

...K fold cross validation
...using stratified K fold cross validation...

\subsubsection{Confusion Matrices}
"Normal" confusion matrix and "Warnings" confusion matrix...

\section{Usage Example}

\begin{listing}[H]
    \caption[callstatplexer]{: Example usage of Frontier}
    \label{list:callstatplexer}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}

        from Frontier import frontier
        from Frontier.IO import DataReader, TargetReader

        data_dir = "/home/sam/Projects/owl_classifier/data/"
        target_path = "/home/sam/Projects/owl_classifier/targets.txt"

        CLASSES = {
                "hoot": {
                    "names": ["owl", "owls"],
                    "code": 1,
                },
                "unhoot": {
                    "names": ["cat", "dog", "pancake"],
                    "code": 0,
                },
        }

        statplexer = frontier.Statplexer(data_dir,
                                         target_path,
                                         CLASSES,
                                         DataReader,
                                         TargetReader)
    \end{minted}
\end{listing}

Constructing the Statplexer requires the following arguments:

\begin{itemize}
    \item \textbf{data\_dir} \textit{String}\hfill\\
        Root data directory under which all files will be parsed for observation data
    \item \textbf{target\_path} \textit{String}\hfill\\
        Path to file to be parsed for observation targets
    \item \textbf{CLASSES} \textit{Dictionary}\hfill\\
        A dictionary of user specified class labels defined as described in
        Chapter~\ref{chap:classes}
    \item \textbf{DataReader} \textit{Module}\hfill\\
        Module containing the class (of the same name) to be used to parse each
        file in the \textit{data\_dir} tree for observation data
    \item \textbf{TargetReader} \textit{Module}\hfill\\
        Module containing the class (of the same name) to be used to parse the
        \textit{target\_path} file for target data
\end{itemize}


\section{Testing}

...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

