\chapter{Frontier}
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%TODO Better description of Frontier
This chapter introduces \textbf{Frontier}: the main programming effort for this
part of the project. Frontier is a Python package that serves as a data manager,
providing both interfaces to read inputs into structures in memory and to
retrieve them in formats acceptable to a machine learning framework.

\section{Design}
\subsection{Purpose}

Frontier's purpose is to supplement analysis with \textbf{scikit-learn} by
allowing a user to read in and parameterise data in a format that can then be
used for analysis by the \textbf{scikit-learn} library.  Frontier was designed
to simplify the process of setting up machine learning tasks and enable
experiment repeatability by removing the need for users to spend time
constructing classes and functions to parse their input data and to just get on
with analysis using \textbf{scikit-learn}.

Initially Frontier was to act as a wrapper around \textbf{scikit-learn},
essentially removing the end user's interaction with the library and merely
providing an interface for data to be passed in and some sort of classifier to
be returned. However this quite clearly limited Frontier's audience by tying it
to a particular framework and would quickly become unmanageable in the task of
providing wrappers for all aspects of an external library.

Instead it was decided that Frontier would be used alongside a user's chosen
machine learning framework, providing a useful API to parse and extract
observations and variables from input data and arrange them in structures
suitable for processing with \textbf{scikit-learn}.

If possible, Frontier could also handle any objects returned, displaying or
logging any textual or graphical information pertaining to a returned
classifier's accuracy to assist a user in the ongoing performance monitoring of
changes to used data subsets or parameters.


\subsection{Format}

Frontier is designed as a Python package, allowing a user to import its
functionality in to other programs. The result of this project's technical
output could almost be considered as two separate entities: Frontier itself, the
package designed to ease user interaction with scikit-learn and \textbf{Front},
a Python script which implements Frontier's functionality in order to interact
with scikit-learn to conduct analysis on the \textbf{auto\_qc} data.


\subsection{Method}

.. the result of abstracting code and tools created during the use of
\textbf{scikit-learn} for analysis of the current \textbf{auto\_qc} system
.. initially hard-coded to suit the specific needs of the project but followed
an evolutionary design process...

designed specifically for the given learning problem, with hard coded
classes and encodings...

...a major refactoring to remove hard-coded classes from \textbf{Frontier} which
enable it to be used as a more general purpose tool, users now specify the
classes and associated labels and encodings (for example those used by Front are
demonstrated in Listing~\ref{fig:FrontierClasses})...


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Concepts}

In this section we introduce some terminology and ideas that will assist
understanding of the application's purpose and terminology used in the following
implementation section.


\subsection{Observations and Parameters}

An \textbf{observation} refers to a distinct object or "thing" from which we
will attempt to understand the relationship between its known properties and
classification to be able to label future observations with unknown class based
on those properties. In the context of this project, this would be a lanelet.
Other documentation in the field may use the term \textit{sample} but to avoid
confusion with the definition of sample introduced in
Chapter~\ref{chap:samplelanelanelets} we will use the term observation.

The aforementioned \textit{properties} or \textit{attributes} of an observation
will be referred to as the \textbf{parameters} of that observation.
Traditionally these may be described as \textit{features} but it was felt that
this wording may have connotations with discrete data. Early versions of
Frontier referred to parameters as \textit{regressors}, using terminology from
statistical modelling. This wording was dropped to remove any confusion between
regression and classification machine learning problems.


\subsection{Data and Targets}
%TODO Mention dependent and explanatory variables?

\textbf{Data} will be used somewhat generically to refer to a matrix in which
observations act as rows and their parameters act as columns. It is expected
that all observations will have the same set of parameters.

For problems of a classification nature such as ours, an observation's
\textbf{target} is the known classification of that particular observation.
Depending on the context of the learning problem targets may be discovered
manually (\textit{e.g.} counting leaves from images of plants, one will need to
manually count all the leaves in the image before being able to use it for
learning) or as the output from another system such as \textbf{auto\_qc}.

In the context of this project where the objective is to begin learning the
rules of \textbf{auto\_qc} the targets refer to whether a particular lanelet
observation was labelled as a pass, fail or warn by the current system.


\subsection{Class Labels and Codes}

An observation's target may also be known as its \textbf{label}. A labelled
observation is said to be a member of that label's \textbf{class}. For example a
lanelet that has failed \textbf{auto\_qc} is said to be labelled as a fail and
is a member of the class of failures.

String based class labels can pose difficulties when handling data later on, not
only taking more memory to store as opposed to a type such as an integer but
also introducing accidental subsetting or discarding of data whose labels differ
unexpectedly. For example are "fail", ,"fial", "FAIL" and "Failed" supposed to
be members of the same class?

%TODO Why?
Often such labels are \textbf{encoded} in to simpler types such as integers.


\subsection{Training and Testing}

...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}

This section investigates the implementation of Frontier's major components:

\begin{itemize}
    \item Handling of input, readers, sanity checking
    \item Storage of read data in memory
    \item Retrieval
    \item Interaction with scikit-learn
\end{itemize}


\subsection{Class Definitions}
\label{chap:classes}

Frontier was designed to support classification machine learning problems, to
adequately support this task, the package must be aware of each of the possible
classes in the problem space. Early versions of Frontier were specifically
designed for training and testing data from \textbf{auto\_qc} and could only
support encoding and decoding of the pass, fail and warn classes.

However this implementation was clearly esoteric and held little to no further
use outside the domain of the project's learning task. What were to happen if
a class label was added or removed in future? Most likely many lines of code
would need to be re-written to handle such cases; the package was inflexible.

...if we were to add another
class label, the definition would merely need to be included to the CLASSES
(Listing~\ref{fig:FrontierClasses}) variable passed when the Statplexer is
constructed. But use is therefore not merely limited to our problem but rather
any machine learning problem where you'd like to simplify your interactions
which a very large dataset.

\begin{listing}[H]
    \caption[FrontierClasses]{Class definitions for auto\_qc as passed to Frontier}
    \label{fig:FrontierClasses}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}
        CLASSES = {
                "pass": {
                    "class": ["pass"],
                    "names": ["pass", "passed"],
                    "code": 1,
                },
                "fail": {
                    "class": ["fail"],
                    "names": ["fail", "failed"],
                    "code": -1,
                },
                "warn": {
                    "class": ["warn"],
                    "names": ["warn", "warning"],
                    "code": 0,
                },
        }
    \end{minted}
\end{listing}

...this allows Frontier to be compatible with almost any learning task, you
merely specify the correct data and target readers, the known classes and call
the \textbf{Statplexer}...


\subsection{Input Handling}

Frontier's modular nature allows users to write their own Python classes to read
data from any form of input file or stream. Two examples of which are the
classes used to read from the "bamcheckr'd files" documented in
Appendix~\ref{app:bamcheckr} and the \textbf{auto\_qc} decisions matrix briefly
demonstrated in Appendix~\ref{app:aqc_matrix}.

These classes are described as \textbf{Readers} and implement a common base
class, \textbf{AbstractReader} which takes care of
setting up the file handler, including functions to both close and iterate over
the file's contents. It will also automatically call its own
\textbf{process\_file} function that skips over any header lines before passing
each line in the file stripped of any newline characters to \textbf{process\_line}.

It is expected that derived classes will at least provide their own
implementations for \textbf{process\_line} and \textbf{get\_data}. Failing to do
so will cause Frontier to throw a \textbf{NotImplementedError} when attempting
to use the class to read data.

\textbf{process\_line} defines the line handling operations that extract and store
desired data found in a given line. This responsibility includes returning None
for lines that contain comments and irrelevant data.

\textbf{get\_data} must return any read in data in a suitable structure for
storage by Frontier. Typically this will be a Python dictionary using some
unique identifier for each observation as a key, mapping to an arbitrary value
or object containing that observation's parameters. Further discussion on
Frontier's storage of data and targets is to follow.

The \textbf{AbstractReader} class is designed to simplify the process of reading
in observations and their targets for end users, however it is still up to the
author of the dervied class to set up any structures to store data (which cannot
be done automatically without likely enforcing potentially unhelpful
constraints) before initialisation of the inherited base class (via the call to
\textbf{super}) as shown in Listing~\ref{list:superreader}.

\begin{listing}[H]
    \caption[superreader]{: Extract from \textbf{BamcheckReader} class
        documenting initialisation of necessary data structures and calling
        for initialisation of its inherited base class}
    \label{list:superreader}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}
        class BamcheckReader(AbstractReader):
            [...]

            def __init__(self, filepath, CLASSES, auto_close=True):
                self.summary = SummaryNumbers()
                self.indel = IndelDistribution()
                super(BamcheckReader, self).__init__(filepath, CLASSES, auto_close, 0)

            [...]
    \end{minted}
\end{listing}

As shown in Listing~\ref{list:superreader}, the initialisation of the
\textbf{AbstractReader} allows four arguments:

\begin{itemize}
    \item \textbf{filepath} \textit{String}\hfill\\
        A relative or absolute path to a file from which to extract data or
        targets
    \item \textbf{CLASSES} \textit{Dictionary}\hfill\\
        A dictionary of user specified learning classes defined as described in
        Chapter~\ref{chap:classes}
    \item \textbf{auto\_close} \textit{Boolean, Optional}\hfill\\
        Whether or not to close the file handle immediately after executing
        \textbf{process\_file}, this is True by default to prevent either memory
        leaking when users are reading in a large number of files and are
        perhaps unaware that they require closing or the throwing of IOError
        caused by having too many file handles open at once
    \item \textbf{header} \textit{Integer, Optional}\hfill\\
        The number of lines to ignore before the reader should begin
        passing stripped lines to \textbf{process\_line}, defaults to 0
\end{itemize}

Currently it is also the responsibility of the author of a derived class to
perform relevant sanity checking of any extracted data. For example the
\textbf{BamcheckReader} class checks for the presence of multiple entries of a
particular metric which will print a notice if found, unless the entries have
differing values, upon which an exception is thrown and the process is halted.

Once a reader has been defined for a particular file format, a user need only
provide a directory of files to be parsed and the name of the class designed to
complete the parsing. Frontier will then take care of executing the parsing
process on all files in the directory. After a derived reader has completed file
handling, Frontier will call its \textbf{get\_data} function to
"move"\footnote{Rather, a pointer to the address of the extracted data's
dictionary hashmap will be copied to memory inside a Frontier class} the
extracted data to its own storage.

%TODO Cite algorithm
At this point Frontier will also check the integrity of the data, primarily that
all parameters have a non-zero variance. Users will be warned when this
requirement is violated; parameters with no variance cannot provide much
information for successful classification as their values are equal for all
class labels!

%FUTURE
In future it would be useful to investigate whether it would be feasible to
perform such sanity checking in a generic manner to ensure it could be applied
to a wide enough range of scenarios to make it worth including functionality in
the \textbf{AbstractReader} directly.

With more time, future improvements could overhaul the reader interfaces
to allow users to simply specify the format of a file in a string that can be
parsed by Frontier's IO subpackage, rather than having to write their own derived
class. Classes could also list file extensions they are capable of processing
which could potentially be used to automatically determine which readers to use
without requiring the user to explicitly specify.


\subsection{Storage}

% TODO Cite tests?
Frontier specifies a class called the \textbf{Statplexer}\footnote{A somewhat
contrived contraction of 'Statistics Multiplexer'} which provides users with a
single point of access to all read in data. The reader interfaces described in
the previous chapter implement their own loading functions which populate the
\textbf{\_data} and \textbf{\_targets} class members of the \textbf{Statplexer}
object.

Although these attributes can be manipulated directly (and indeed they are for
testing purposes) the leading underscore follows a popular convention defined in
Python's style guideline, PEP8\citep{pep8}, where class members with such
leading underscores should be treated as non-public. Python doesn't have private
variables such as those that may be found in other languages like Java, indeed
the Python style guide points out that "no attribute is really private in
Python"\citep{pep8}. In an interesting StackOverflow answer on the subject, a
user describes that this is "cultural"\citep{so:pythonprivate} and that Python
programmers are trusted not "mess around with those private members".

Frontier provides functions to allow controlled access to get and set data
stored in these pseudo-private \textbf{\_data} and \textbf{\_targets} members.

%TODO Find better citation (Python book)
...\textbf{\_data} and \textbf{\_targets} are Python dictionaries, a structure
in which hashed keys are mapped to an arbitrary value or object. Python
dictionaries offer $O$(1) (constant) lookup\citep{py:timecomplexity} access
...more importantly querying the structure for whether it contains a particular
key can also be performed in constant $O$(1) as opposed to searching a list for
membership...

...when input data is parsed, the relevant reader class is expected to locate an
appropriate id for an observation, in our case, a sample's label...
...this id is used as a key for both the \textbf{\_data} and \textbf{\_targets}
dictionaries, which map this id to some structure containing that observation's
parameter values and classification respectively...

...why not a list?
...numpy lists also require the length to be known when they are created which
would not be possible without reading through all the input files first,
somewhat of a waste of time...

...primarily because the number of inputs is unknown, a list structure is
represented as a contiguous array in memory, causing very expensive copying
operations when the list needs to be resized...

...could we not load data in to a list at the end of input file reading?
...the load\_data function allows data to be loaded in to the
\textbf{Statplexer} at any time, thus requiring use of the expensive memory
copying operations when the list once again needs to be resized...


...an issue with use of a dictionary however is by default they are unsorted,
not only this but the order in which the keys are iterated over will be
undefined...
...currently this causes the list of keys to require sorting each time a user
queries the Statplexer API for data... as obviously the parameters and targets
must map one-to-one in a predictable and repeatable manner.
%TODO Figure to show mapping between container elements

...through testing of the 13,455 observations it would seem that this sorting
operation is inexpensive... and indeed seems a fair price to pay for having
constant lookup speed on membership as well as being able to access an object by
its id rather than knowing where it is in a list...

...although the latter point is somewhat easily fixed for an array
implementation by using a dictionary to provide a mapping between a sample name
and where it is stored in an array...

...also storage of classes (used for access to Frontier utils)
...utils to classify a label, encode a class, decode a class and count a
class...


\subsection{Retrieval}
The Statplexer is designed to provide the user methods in which to extract
desired data in a format suitable for parsing with an external framework or
library, in our case; scikit-learn

...leverages \textbf{numpy}...
...some of the methods provided include:

\begin{description}
    \item[list\_regressors] Retrieve a list of all parameters
    \item[find\_regressors] Retrieve a list of parameters containing any of the
        input strings as a substring
    \item[exclude\_regressors] Retrieve a list of parameters which do not
        contain any of the input strings as a substring, or if needed an exact
        match
\end{description}

...data is returned sorted by key, with parameters sorted alphanumerically...
...targets map 1:1 with the data array...

\begin{description}
    \item[get\_data\_by\_regressors] Return data for each observation, but only
        return columns for the parameters in the given list
    \item[get\_data\_by\_target] Return data for each observation that have been
        classified in one of the targets specified and additionally only
        return columns for the parameters in the given list
\end{description}

\subsection{Interaction with scikit-learn}
\subsubsection{Cross Validation}

...method in which to measure classification accuracy...
...potentially use a weighting to penalise mistakes in smaller classes...

...K fold cross validation
...using stratified K fold cross validation...

\subsubsection{Confusion Matrices}
"Normal" confusion matrix and "Warnings" confusion matrix...

\subsection{Parameter Selection}
...important to find the "best" parameters
...what is best? scikit-learn uses total gini information

...frontier uses two methods:
\begin{itemize}
    \item Backward elimination; pruning parameters with the lowest total gini
    \item Call scikit-learn's SelectKBest
\end{itemize}


* incorrect degrees of freedom
* warnings: /usr/lib64/python2.7/site-packages/sklearn/feature\_selection/univariate\_selection.py:256: RuntimeWarning: invalid value encountered in divide, causing NaN
* Replaced univariate\_selection with version from master
* needed use force np.float64
...actually data was 0... gg :(

\section{Testing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Contributions to bamcheckr}
\begin{minted}[mathescape,
               %linenos,
               numbersep=5pt,
               gobble=4,
               frame=lines,
               framesep=2mm]{r}
    install.packages("devtools")
    library(devtools)

    # Install directly from github repository
    install_github("samstudio8/seq_autoqc", subdir="bamcheckr")

    # Install from local directory
    install("/home/sam/Projects/seq_autoqc/bamcheckr")

\end{minted}
Takes 5.5s on average, 16.1s with ratio due to inefficient implementation
for overlapping\_base\_duplicate\_percentage
re-wrote in Python...


...R CMD BATCH issue

...Fixed a graph plotting failure.
...Writing additional routines...


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

