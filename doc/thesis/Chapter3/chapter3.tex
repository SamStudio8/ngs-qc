\chapter{Frontier}
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%TODO Better description of Frontier
This chapter introduces \textbf{Frontier}: the main programming effort for this
part of the project. Frontier is a Python package that serves as a data manager,
providing both interfaces to read inputs into structures in memory and to
retrieve them in formats acceptable to a machine learning framework.

\section{Design}
\subsection{Purpose}

Frontier's purpose is to supplement analysis with \textbf{scikit-learn} by
allowing a user to read in and parameterise data in a format that can then be
used for analysis by the \textbf{scikit-learn} library.  Frontier was designed
to simplify the process of setting up machine learning tasks and enable
experiment repeatability by removing the need for users to spend time
constructing classes and functions to parse their input data and to just get on
with analysis using \textbf{scikit-learn}.

Initially Frontier was to act as a wrapper around \textbf{scikit-learn},
essentially removing the end user's interaction with the library and merely
providing an interface for data to be passed in and some sort of classifier to
be returned. However this quite clearly limited Frontier's audience by tying it
to a particular framework and would quickly become unmanageable in the task of
providing wrappers for all aspects of an external library.

Instead it was decided that Frontier would be used alongside a user's chosen
machine learning framework, providing a useful API to parse and extract
observations and variables from input data and arrange them in structures
suitable for processing with \textbf{scikit-learn}.

If possible, Frontier could also handle any objects returned, displaying or
logging any textual or graphical information pertaining to a returned
classifier's accuracy to assist a user in the ongoing performance monitoring of
changes to used data subsets or parameters.


\subsection{Format}

Frontier is designed as a Python package, allowing a user to import its
functionality in to other programs. The result of this project's technical
output could almost be considered as two seperate entities: Frontier itself, the
package designed to ease user interaction with scikit-learn and \textit{Front},
a Python script which implements Frontier's functionality in order to interact
with scikit-learn to conduct analysis on the \textbf{auto\_qc} data.


\subsection{Method}

.. the result of abstracting code and tools created during the use of
\textbf{scikit-learn} for analysis of the current \textbf{auto\_qc} system
.. initially hardcoded to suit the specific needs of the project but followed
an evolutionary design process...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
...we investigate the following implementation stories...:

\begin{itemize}
    \item User input, readers, sanity checking
    \item Storage of read data in memory
    \item Retrieval
    \item Interaction with scikit-learn
\end{itemize}


\subsection{Input Handling}
Frontier's modular nature allows users to write their own Python classes to read
data from any form of input. Two examples of which are the provided classes used
to read from the "bamcheckr'd files" as seen in Appendix~\ref{app:bamcheckr}...
as well as the auto\_qc output matrix briefly demonstrated in Appendix~\ref{app:aqc_matrix}...

Initially designed specically for the given learning problem, with hard coded
classes and encodings...

...a major refactoring to remove hard-coded classes from \textbf{Frontier} which
enable it to be used as a more general purpose tool, users now specify the
classes and associated labels and encodings (for example those used by Front are
demonstrated in Listing~\ref{fig:FrontierClasses})...

...if we were to add another
class label, the definition would merely need to be included to the CLASSES
(Listing~\ref{fig:FrontierClasses}) variable passed when the Statplexer is
constructed. But use is therefore not merely limited to our problem but rather
any machine learning problem where you'd like to simplify your interactions
which a very large dataset.

\begin{listing}[H]
    \caption[FrontierClasses]{Class definitions for auto\_qc as passed to Frontier}
    \label{fig:FrontierClasses}
    \begin{minted}[mathescape,
                %linenos,
                numbersep=5pt,
                gobble=8,
                frame=lines,
                framesep=2mm]{python}
        CLASSES = {
                "pass": {
                    "class": ["pass"],
                    "names": ["pass", "passed"],
                    "code": 1,
                },
                "fail": {
                    "class": ["fail"],
                    "names": ["fail", "failed"],
                    "code": -1,
                },
                "warn": {
                    "class": ["warn"],
                    "names": ["warn", "warning"],
                    "code": 0,
                },
        }
    \end{minted}
\end{listing}

...this allows Frontier to be compatable with almost any learning task, you
merely specify the correct data and target readers, the known classes and call
the \textbf{Statplexer}...

% Cite algorithm
...Frontier also checks each parameter for variance, warning users when this
requirement is violated... (a parameter with 0 variance is pretty useless...)

\subsection{Storage}

Frontier provides a class called the \textbf{Statplexer}\footnote{A somewhat
contrived contraction of Statistics Multiplexer} which houses all read in data.
...whilst the stored data and targets can be manipulated directly (and indeed
they are for testing purposes) it is unrecommended and controlled access can be
gained via Frontier's API...

...data and targets stored in python dictionaries, offering constant lookup
access...
...must however be sorted each time data is requested...
...this seems a fair price to pay (although if desired we could use a
collection) for having constant lookup speed for checking on dictionary
membership and indexing by a user-friendly string...(for example a sample could
be retrieved using its name rather than knowing where in the array it
resides)...

%TODO Rambling
...perhaps in future data and targets can be stored in arrays with a dict to
provide a mapping between a sample name and its location in the array...
...this allows for lookups to be completed in O(1) time whilst maintaining an
array under the hood...

...also storage of classes (used for access to Frontier utils)
...utils to classify a label, encode a class, decode a class and count a
class...


\subsection{Retrieval}
The Statplexer is designed to provide the user methods in which to extract
desired data in a format suitable for parsing with an external framework or
library, in our case; scikit-learn

...leverages \textbf{numpy}...
...some of the methods provided include:

\begin{description}
    \item[list\_regressors] Retrieve a list of all parameters
    \item[find\_regressors] Retrieve a list of parameters containing any of the
        input strings as a substring
    \item[exclude\_regressors] Retrieve a list of parameters which do not
        contain any of the input strings as a substring, or if needed an exact
        match
\end{description}

...data is returned sorted by key, with parameters sorted alphanumerically...
...targets map 1:1 with the data array...

\begin{description}
    \item[get\_data\_by\_regressors] Return data for each observation, but only
        return columns for the parameters in the given list
    \item[get\_data\_by\_target] Return data for each observation that have been
        classified in one of the targets specified and additionally only
        return columns for the parameters in the given list
\end{description}

\subsection{Interaction with scikit-learn}
\subsubsection{Cross Validation}

...method in which to measure classification accuracy...
...potentially use a weighting to penalise mistakes in smaller classes...

...K fold cross validation
...using stratified K fold cross validation...

\subsubsection{Confusion Matrices}
"Normal" confusion matrix and "Warnings" confusion matrix...

\subsection{Contributions to bamcheckr}
\begin{minted}[mathescape,
               %linenos,
               numbersep=5pt,
               gobble=4,
               frame=lines,
               framesep=2mm]{r}
    install.packages("devtools")
    library(devtools)

    # Install directly from github repository
    install_github("samstudio8/seq_autoqc", subdir="bamcheckr")

    # Install from local directory
    install("/home/sam/Projects/seq_autoqc/bamcheckr")

\end{minted}
Takes 5.5s on average, 16.1s with ratio due to inefficient implementation
for overlapping\_base\_duplicate\_percentage
re-wrote in Python...


...R CMD BATCH issue

...Fixed a graph plotting failure.
...Writing additional routines...

\subsection{Parameter Selection}
...important to find the "best" parameters
...what is best? scikit-learn uses total gini information

...frontier uses two methods:
\begin{itemize}
    \item Backward elimination; pruning parameters with the lowest total gini
    \item Call scikit-learn's SelectKBest
\end{itemize}


* incorrect degrees of freedom
* warnings: /usr/lib64/python2.7/site-packages/sklearn/feature\_selection/univariate\_selection.py:256: RuntimeWarning: invalid value encountered in divide, causing NaN
* Replaced univariate\_selection with version from master
* needed use force np.float64
...actually data was 0... gg :(

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Testing}

